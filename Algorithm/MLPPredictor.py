import os
import sys
import time
import numpy as np
import datetime
from typing import Dict, Any, Optional
from tensorflow.keras.models import load_model
from joblib import load as joblib_load

# ìƒìœ„ í´ë” ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from AlgorithmInterface import AlgorithmBase


class KerasMLPPredictor(AlgorithmBase):
    """
    Keras ê¸°ë°˜ MLP ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¬´ê²Œ ë° ìœ„ì¹˜ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ (ì„¼ì„œ ë³€í™”ëŸ‰ ê¸°ë°˜)
    """

    def __init__(self):
        super().__init__(
            name="KerasMLPPredictor",
            description="Keras ê¸°ë°˜ MLP ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¬´ê²Œ ë° ìœ„ì¹˜ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ (ì„¼ì„œ ë³€í™”ëŸ‰ ê¸°ë°˜)",
            model_path="../model/mlp_20250403_135334_best.h5"
        )
        self.scaler_path = "../model/scaler_20250403_135334.save"
        self.input_data.append("value")

        # ì„¼ì„œ ì´ˆê¸°ê°’ ì €ì¥ìš©
        self.initial_values = {}

        # ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        model_abspath = os.path.join(os.path.dirname(os.path.abspath(__file__)), self.model_path)
        scaler_abspath = os.path.join(os.path.dirname(os.path.abspath(__file__)), self.scaler_path)

        self.input_data.append("value")

        try:
            self.model = load_model(model_abspath, compile=False)
            self.scaler = joblib_load(scaler_abspath)
            print("ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"ëª¨ë¸ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None
            self.scaler = None

    def _load_model(self):
        path = os.path.join(current_dir, self.model_path) if not os.path.isabs(self.model_path) else self.model_path
        if os.path.exists(path):
            return load_model(path, compile=False)
        else:
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {path}")

    def _load_scaler(self):
        path = os.path.join(current_dir, self.scaler_path) if not os.path.isabs(self.scaler_path) else self.scaler_path
        if os.path.exists(path):
            return joblib.load(path)
        else:
            print("scaler error")
            raise FileNotFoundError(f"ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì—†ìŒ: {path}")

    def preprocess_data(self, data: Union[list, dict]) -> Dict[str, Any]:
        if self.model is None or self.scaler is None:
            return {'error': "ëª¨ë¸ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

        sensor_values = []

        # ì§ì ‘ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì€ ê²½ìš°
        if isinstance(data, list) and len(data) == 4:
            try:
                sensor_values = [float(x) for x in data]
            except Exception:
                return {'error': 'ì„¼ì„œ ê°’ í˜•ì‹ ì˜¤ë¥˜'}
        # JSON í˜•íƒœ(dict)ì¸ ê²½ìš°ë„ ì—¬ì „íˆ ì§€ì›
        elif isinstance(data, dict) and all(k in data for k in ['A', 'B', 'C', 'D']):
            try:
                sensor_values = [float(data[k]) for k in ['A', 'B', 'C', 'D']]
            except Exception:
                return {'error': 'ì„¼ì„œ ê°’ í˜•ì‹ ì˜¤ë¥˜'}
        else:
            return {'error': 'ìœ íš¨í•œ ì„¼ì„œ ì…ë ¥ì´ ì—†ìŠµë‹ˆë‹¤'}

        input_array = np.array([sensor_values])
        scaled_input = self.scaler.transform(input_array)

        return {'processed_values': scaled_input}

    def process(self) -> Dict[str, Any]:

        try:
            if self.model is None or self.scaler is None:
                return {'error': "ëª¨ë¸ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

            # í˜„ì¬ ì„¼ì„œê°’ ì¶”ì¶œ
            current_values = {
                "VCOM1": self.data["VCOM1"]["value"],
                "VCOM2": self.data["VCOM2"]["value"],
                "VCOM3": self.data["VCOM3"]["value"],
                "VCOM4": self.data["VCOM4"]["value"]
            }

            # ì´ˆê¸°ê°’ ì €ì¥ (ìµœì´ˆ ì‹¤í–‰ ì‹œì—ë§Œ)
            for key in current_values:
                if key not in self.initial_values:
                    self.initial_values[key] = current_values[key]

            # ë³€í™”ëŸ‰ ê³„ì‚°
            delta_values = [
                current_values["VCOM1"] - self.initial_values["VCOM1"],
                current_values["VCOM2"] - self.initial_values["VCOM2"],
                current_values["VCOM3"] - self.initial_values["VCOM3"],
                current_values["VCOM4"] - self.initial_values["VCOM4"]
            ]

            # ìŠ¤ì¼€ì¼ë§ ë° ì˜ˆì¸¡
            input_array = np.array(delta_values).reshape(1, -1)
            scaled_input = self.scaler.transform(input_array)
            predictions = self.model.predict(scaled_input)

            weight = float(predictions[0][0])
            position = int(round(predictions[0][1]))

            return {
                'weight': weight,
                'position': position,
                'raw_predictions': predictions.tolist(),
                'input_values': current_values,
                'delta_values': delta_values
            }
        except Exception as e:
            return {'error': f"ëª¨ë¸ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}"}

    def execute(self, input_data: Optional[Union[list, dict]] = None) -> Dict[str, Any]:
        self.data = input_data
        # ì•Œê³ ë¦¬ì¦˜ ë³„ ì…ë ¥ ë°ì´í„° ì •ì˜ì— ë”°ë¼ í›„ì²˜ë¦¬ ìˆ˜í–‰
        self.preprocessing()
        try:
            self.is_running = True
            start_time = time.time()

            results = self.process()

            self.output_data = results
            self.execution_time = time.time() - start_time

            self.execution_history.append({
                'timestamp': time.time(),
                'input_keys': list(self.input_data.keys() if isinstance(self.input_data, dict) else []),
                'output_keys': list(self.output_data.keys() if isinstance(self.output_data, dict) else []),
                'execution_time': self.execution_time
            })

            return self.output_data
        except Exception as e:
            return {'error': f"ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ì˜¤ë¥˜: {e}"}
        finally:
            self.is_running = False

    def reset_initial_values(self):
        """ì´ˆê¸° ì„¼ì„œê°’ ì¬ì„¤ì •"""
        self.initial_values = {}
        print("ğŸŒ€ ì´ˆê¸° ì„¼ì„œê°’ì´ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤.")


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    predictor = KerasMLPPredictor()

    new_test_data = {
        'VCOM3': {'timestamp': '17_40_42_396', 'value': 422, 'sub1': 460, 'sub2': 464, 'Data_port_number': 'VCOM3',
                  'timestamp_dt': datetime.datetime(2025, 4, 6, 17, 40, 42, 396000)},
        'VCOM4': {'timestamp': '17_40_42_397', 'value': 455, 'sub1': 455, 'sub2': 479, 'Data_port_number': 'VCOM4',
                  'timestamp_dt': datetime.datetime(2025, 4, 6, 17, 40, 42, 397000)},
        'VCOM1': {'timestamp': '17_40_42_399', 'value': 406, 'sub1': 405, 'sub2': 409, 'Data_port_number': 'VCOM1',
                  'timestamp_dt': datetime.datetime(2025, 4, 6, 17, 40, 42, 399000)},
        'VCOM2': {'timestamp': '17_40_42_400', 'value': 455, 'sub1': 443, 'sub2': 420, 'Data_port_number': 'VCOM2',
                  'timestamp_dt': datetime.datetime(2025, 4, 6, 17, 40, 42, 400000)}
    }

    # ì„¼ì„œì—ì„œ ì§ì ‘ ìˆ˜ì‹ í•œ í˜•íƒœ (ì˜ˆ: listë¡œ ë“¤ì–´ì˜¤ëŠ” ê²½ìš°)
    test_input = [2, 6, 76, -33]

    result = predictor.execute(new_test_data)

    print(f"ì…ë ¥ê°’: {new_test_data}")
    print(f"ì˜ˆì¸¡ ë¬´ê²Œ: {result.get('weight')} kg")
    print(f"ì˜ˆì¸¡ ìœ„ì¹˜: {result.get('position')}")
    print(f"ë³€í™”ëŸ‰: {result.get('delta_values')}")
    print(predictor.get_output_data())
    print(predictor.get_history())
